{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\games\\.conda\\envs\\pytorch_cuda118_py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\CodeProjects\\TransformerFromScratch\\translate.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_filename)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SOURCE: --f=c:\\Users\\games\\AppData\\Roaming\\jupyter\\runtime\\kernel-v34f6bdc514d18b4fb2ff21922018daf1e71aa1a34.json\n",
      " PREDICTED: \" Si                  .  "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, get_latest_weight_filepath, get_weight_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "from translate import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Max Src Len: {} 309\n",
      "Max Tgt Len: {} 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\games\\AppData\\Local\\Temp\\ipykernel_20992\\3584481288.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(model_filename)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = get_latest_weight_filepath(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: To leave your son, or to continue in this degrading situation?'\n",
      "    TARGET: Lasciare il figlio o continuare a vivere in questa situazione umiliante?\n",
      " PREDICTED: Lasciare il figlio o continuare a vivere in questa situazione umiliante ?\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: No, my children will not be like these!'\n",
      "    TARGET: No, io non avrò bambini come questi».\n",
      " PREDICTED: No , amico mio , non c ’ è più di questi figli .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: His hair was long and black, not curled like wool; his forehead very high and large; and a great vivacity and sparkling sharpness in his eyes.\n",
      "    TARGET: Lunga e nera erane la capellatura, non crespa a guisa di lana; spaziosa ed alta la fronte; vivacissima e scintillante l’acutezza delle sue pupille.\n",
      " PREDICTED: Il suo collo era lungo , , dai , la fronte e la fronte ; un gran gran peso era e .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Unused as I was to strangers, it was rather a trial to appear thus formally summoned in Mr. Rochester's presence.\n",
      "    TARGET: Era una prova per me, così poco assuefatta a vedere estranei, il presentarsi al signor Rochester.\n",
      " PREDICTED: Era stata una delle mie scolare troppo da un signor Rochester .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: At this moment the door of the house opened, and a large plate came skimming out, straight at the Footman's head: it just grazed his nose, and broke to pieces against one of the trees behind him.\n",
      "    TARGET: In quell'istante la porta si aprì, e un gran piatto volò verso la testa del valletto, gli sfiorò il naso e si ruppe in cento pezzi contro un albero più oltre.\n",
      " PREDICTED: In quel momento il Cappellaio aprì una porta , e un piatto , un po ' di fumo . Il Cappellaio si alzò in alto e cadde in alto la testa in acqua .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: LEVIN EMPTIED HIS GLASS and they were silent for a while.\n",
      "    TARGET: Levin bevve la sua coppa e i due rimasero in silenzio. — Una cosa nuova devo dirti.\n",
      " PREDICTED: Levin lesse la sua coppa e la porta erano ancora andati .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: In the middle of the winter he spent a very dull week.\n",
      "    TARGET: A metà dell’inverno Vronskij trascorse una settimana molto noiosa.\n",
      " PREDICTED: Nel mezzo della città egli giunse molto in settimana .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: And he really had flushed with vexation and had said something disagreeable.\n",
      "    TARGET: E invero, egli era diventato rosso di collera e aveva detto qualcosa di spiacevole.\n",
      " PREDICTED: E proprio così , proprio così , con le sue parole , aveva detto qualcosa di spiacevole .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: \"Down, Pilot!\" I again said.\n",
      "    TARGET: — Giù, Pilato! — ripetei.\n",
      " PREDICTED: — All ' ora , Bessie , — dissi .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Is not the thing feasible?\n",
      "    TARGET: Non è forse cosa fattibile?\n",
      " PREDICTED: Non è forse forse il diritto di agire ?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "    SOURCE: Why do I need to translate this?\n",
      " PREDICTED: Perché dovrei di me  a me ?  "
     ]
    }
   ],
   "source": [
    "t = translate(\"Why do I need to translate this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "        ID: 34\n",
      "    SOURCE: And I came out immediately, for I trembled at the idea of being dragged forth by the said Jack.\n",
      "    TARGET: Uscii subito, perché mi sgomentavo al pensiero di esser condotta fuori dal mio nascondiglio da John.\n",
      " PREDICTED: E riprese per che fui la  la  la  la  la seguente :  "
     ]
    }
   ],
   "source": [
    "t = translate(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
